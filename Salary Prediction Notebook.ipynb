{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on job information, we must predict salaries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the problem in your own words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#import your libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#your info here\n",
    "__author__ = \"Khalid Rahman\"\n",
    "__email__ = \"kirahman2@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. COMPLETED create model container, \n",
    "# 2. test new features\n",
    "# 3. tuning model \n",
    "# 4. Intend on creating new features and seeing how you can improve the model.\n",
    "# Later: -store model in file -load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Clean the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, train_file, train_target_file, test_file, col_cat, col_num, col_id, col_target):\n",
    "        self.col_cat = col_cat\n",
    "        self.col_num = col_num\n",
    "        self.col_id = col_id\n",
    "        self.col_target = col_target\n",
    "        self.train_df = self._create_train_df(train_file, train_target_file)\n",
    "#         self.train_df = self._shuffle_data(self.train_df)\n",
    "        \n",
    "        self.test_df = self._create_test_df(test_file)\n",
    "        \n",
    "    def _create_train_df(self, train_feature_df, train_target_df):\n",
    "        train_target = self._load_file(train_target_df)\n",
    "        train_df = self._load_file(train_feature_df)\n",
    "        train_df = self._join_df(train_df, train_target, col_id)\n",
    "#         train_df = self._preprocessing(train_df)\n",
    "        train_df = self._clean_data(train_df)\n",
    "        train_df = self._label_encode(train_df, self.col_cat)\n",
    "        return train_df\n",
    "    \n",
    "    def _create_test_df(self, test_file):\n",
    "        test_df = self._load_file(test_file)\n",
    "#         test_df = self._preprocessing(test_df)\n",
    "        test_df = self._label_encode(test_df, col_cat)\n",
    "        return test_df\n",
    "\n",
    "    def _shuffle_data(self, train_df):\n",
    "        train_df = shuffle(train_df, random_state=42)\n",
    "        return train_df\n",
    "\n",
    "    def _clean_data(self, df):\n",
    "        train_df = df\n",
    "        train_df = train_df[train_df.salary>0]\n",
    "        return train_df\n",
    "    \n",
    "    def _label_encode(self, train_df, col_cat):\n",
    "        le = LabelEncoder()\n",
    "        for col in col_cat:\n",
    "#             le.fit(train_df[col])\n",
    "#             train_df[col] = le.transform(train_df[col])\n",
    "            train_df[col] = le.fit_transform(train_df[col])\n",
    "        return train_df\n",
    "         \n",
    "    def _join_df(self, train_df, train_target, col_id):\n",
    "        return pd.merge(train_df, train_target, on=col_id, how='inner')\n",
    "    \n",
    "    def _preprocessing(self, train_df):\n",
    "        return train_df.drop(['jobId'], axis=1)\n",
    "\n",
    "    def _load_file(self, file):\n",
    "        return pd.read_csv(file)\n",
    "    \n",
    "train_file = '/Users/krahman/work/salarypredictionportfolio_old/data/train_features.csv'\n",
    "test_file = '/Users/krahman/work/salarypredictionportfolio_old/data/test_features.csv'\n",
    "train_target_file = '/Users/krahman/work/salarypredictionportfolio_old/data/train_salaries.csv'\n",
    "col_cat = ['companyId', 'jobType', 'degree', 'major', 'industry']\n",
    "col_num = ['milesFromMetropolis', 'yearsExperience']\n",
    "col_all = col_cat + col_num\n",
    "col_id = 'jobId'\n",
    "col_target = 'salary'\n",
    "\n",
    "data = Data(train_file, train_target_file, test_file, col_cat, col_num, col_id, col_target)\n",
    "# data.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyId</th>\n",
       "      <th>jobType</th>\n",
       "      <th>degree</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "      <td>999995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.004194</td>\n",
       "      <td>3.505312</td>\n",
       "      <td>2.122665</td>\n",
       "      <td>5.419788</td>\n",
       "      <td>3.000336</td>\n",
       "      <td>11.992407</td>\n",
       "      <td>49.529381</td>\n",
       "      <td>116.062398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.169850</td>\n",
       "      <td>2.291726</td>\n",
       "      <td>1.408911</td>\n",
       "      <td>2.398849</td>\n",
       "      <td>2.000701</td>\n",
       "      <td>7.212390</td>\n",
       "      <td>28.877721</td>\n",
       "      <td>38.717163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           companyId        jobType         degree          major  \\\n",
       "count  999995.000000  999995.000000  999995.000000  999995.000000   \n",
       "mean       31.004194       3.505312       2.122665       5.419788   \n",
       "std        18.169850       2.291726       1.408911       2.398849   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%        15.000000       2.000000       1.000000       4.000000   \n",
       "50%        31.000000       4.000000       2.000000       7.000000   \n",
       "75%        47.000000       6.000000       3.000000       7.000000   \n",
       "max        62.000000       7.000000       4.000000       8.000000   \n",
       "\n",
       "            industry  yearsExperience  milesFromMetropolis         salary  \n",
       "count  999995.000000    999995.000000        999995.000000  999995.000000  \n",
       "mean        3.000336        11.992407            49.529381     116.062398  \n",
       "std         2.000701         7.212390            28.877721      38.717163  \n",
       "min         0.000000         0.000000             0.000000      17.000000  \n",
       "25%         1.000000         6.000000            25.000000      88.000000  \n",
       "50%         3.000000        12.000000            50.000000     114.000000  \n",
       "75%         5.000000        18.000000            75.000000     141.000000  \n",
       "max         6.000000        24.000000            99.000000     301.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.group_df = self.data.train_df.groupby(col_cat)\n",
    "        self.group_df = self._calculate_stats(self.group_df)\n",
    "        self.data.train_df = self._merge_df(data.train_df, self.group_df)\n",
    "        \n",
    "    def _calculate_stats(self, group_df):\n",
    "        group_df = pd.DataFrame({'group_mean': group_df[data.col_target].mean()})\n",
    "        group_df['group_min'] = self.group_df[data.col_target].min()\n",
    "        group_df['group_max'] = self.group_df[data.col_target].max()\n",
    "        group_df['group_std'] = self.group_df[data.col_target].std()\n",
    "        group_df['group_median'] = self.group_df[data.col_target].median()\n",
    "        return group_df\n",
    "    \n",
    "    def _merge_df(self, train_df, group_df):\n",
    "        final_df = pd.merge(left=train_df, right=group_df, how='left', on=col_cat)\n",
    "        final_df = final_df.fillna(0)\n",
    "        return final_df\n",
    "\n",
    "fe = FeatureEngineering(data)\n",
    "# fe.group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = fe.group_df\n",
    "# df_temp[df_temp['group_mean']==130.875000].shape\n",
    "# df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(data.train_df[data.train_df.jobType==0].salary)\n",
    "# years experience? how does years experience play into this? we see a CEO paid  50k and a janitor\n",
    "# sns.distplot(data.train_df[data.train_df.jobType==3].salary)\n",
    "# sns.scatterplot(x = data.train_df[data.train_df.jobType==3].salary, y = data.train_df[data.train_df.jobType==3].yearsExperience, hue=data.train_df.milesFromMetropolis)\n",
    "# print(data.train_df[data.train_df.jobType==3].salary.max())\n",
    "# train_df2 = pd.read_csv('/Users/krahman/work/salarypredictionportfolio_old/data/train_features.csv')\n",
    "# train_target2 = pd.read_csv('/Users/krahman/work/salarypredictionportfolio_old/data/train_salaries.csv')\n",
    "# df1 = pd.concat([train_df2,train_target2],axis=1)\n",
    "# df1[df1['jobType']=='JANITOR'].salary.max()\n",
    "# sns.boxplot(df1[df1['jobType']=='JANITOR'].salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is:\n",
      " GradientBoostingRegressor(alpha=0.1, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=4,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=180,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "The best score is: 314.80121606647765\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_features_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b29650202268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mselected_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_scoring_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_container\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# fe.group_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features_df' is not defined"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, train_features, train_target, model_container, set_cv, num_proc, dir_pred):\n",
    "        self.train_features = train_features\n",
    "        self.train_target = train_target\n",
    "    \n",
    "    def add_model(self, model):\n",
    "        model_container[model] = self._score_model(model, self.train_features, self.train_target, set_cv, num_proc)\n",
    "    \n",
    "    def fit_model(self, model, train_df, train_target):\n",
    "        return model.fit(train_df, train_target)\n",
    "        \n",
    "    def predict_model(self, model_selected, test_df, train_df, train_target):\n",
    "        model = self.fit_model(model_selected, train_df, train_target)\n",
    "        prediction_results = model.predict(test_df)\n",
    "        self._save_prediction(prediction_results)\n",
    "        return prediction_results\n",
    "        \n",
    "    def best_scoring_model(self, model_container):\n",
    "        best_model = min(model_container, key=model_container.get)\n",
    "        best_score = model_container.get(best_model)\n",
    "        self._print_summary(best_model, best_score)\n",
    "        return best_model\n",
    "    \n",
    "    def _print_summary(self, best_model, best_score):\n",
    "        print('The best model is:\\n', best_model)\n",
    "        print('\\nThe best score is:', best_score)\n",
    "        \n",
    "    def _score_model(self, model, train_df, target_train, set_cv, num_proc):\n",
    "        return -1.0*np.mean(cross_val_score(model, train_df, target_train, scoring='neg_mean_squared_error', cv=set_cv, n_jobs=num_proc))\n",
    "\n",
    "    def _save_prediction(self, prediction_results):\n",
    "        prediction_results = pd.DataFrame(prediction_results).to_csv(dir_pred)\n",
    "\n",
    "# train_features_df = data.train_df\n",
    "# train_target_df = train_features_df.pop('salary')\n",
    "\n",
    "# train_features = data.train_df.loc[:1000,:]\n",
    "# train_target = train_features.pop(col_target)\n",
    "# train_features = train_features[col_all]\n",
    "\n",
    "# train_features = fe.group_df.loc[:1000,:]\n",
    "train_features = data.train_df\n",
    "train_features = train_features[['companyId', 'jobType', 'degree', 'major', 'industry',\n",
    "       'yearsExperience', 'milesFromMetropolis', 'group_mean', 'group_min',\n",
    "       'group_max', 'group_std', 'group_median', 'salary']]\n",
    "train_target = train_features.pop(col_target)\n",
    "\n",
    "# train_features = train_features[col_all]\n",
    "# NEXT, MAKE SURE YOU ARE PASSING THE NEW FEATURES INTO THE MODEL!! \n",
    "\n",
    "test_features_df = data.test_df\n",
    "test_features_df = test_features_df[col_all]\n",
    "\n",
    "# fe = FeatureEngineering(data)\n",
    "\n",
    "set_cv = 2\n",
    "num_proc = -1\n",
    "dir_pred = '/Users/krahman/work/salarypredictionportfolio_old/data/prediction/prediction_results.csv'\n",
    "model_container = {}\n",
    "model = Model(train_features, train_target, model_container, set_cv, num_proc, dir_pred)\n",
    "\n",
    "model.add_model(GradientBoostingRegressor(loss='ls', learning_rate=.1, alpha=.1, n_estimators=180, subsample=1, max_depth=4))\n",
    "# model.add_model(GradientBoostingRegressor(n_estimators=40, max_depth=7, loss='ls'))\n",
    "model.add_model(LinearRegression())\n",
    "selected_model = model.best_scoring_model(model_container)\n",
    "model.predict_model(selected_model, test_features_df, train_features_df, train_target_df)\n",
    "\n",
    "# fe.group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-67-08502efc1610>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-08502efc1610>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# we need to ingest a model, ingest parameters, create param_grid\n",
    "class RandomSearch:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    return\n",
    "gs = RandomSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING BY INDUSTRY \n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import time\n",
    "\n",
    "# # before we score it, we need to predict, then inverse transform\n",
    "# def scoring_gbr_gs():\n",
    "#     score_total = 0\n",
    "#     loss_types = ['ls', 'lad', 'huber', 'quantile']\n",
    "#     learning_rate = [.001,.01,.1,.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "#     alpha= [.001,.01,.1,.2,.3,.4,.5,.6,.7,.8,.9,.95]\n",
    "#     n_estimators = [100,200,300,400,600,1000,2000]\n",
    "#     subsample =[1,.9,.8,.7,.6,.5,.4,.3,.2,.1]\n",
    "#     max_depth = [1,2,3,4,5,6,7,8,9,10]\n",
    "#     model_gbr = GradientBoostingRegressor()\n",
    "#     param_grid = dict(\n",
    "#                      loss=['ls'],\n",
    "#                      learning_rate=[.1],\n",
    "#                       alpha=[.1],\n",
    "#                       n_estimators=[180],\n",
    "#                      subsample=[1],\n",
    "#                      max_depth=[4]\n",
    "#                      )\n",
    "#     random = RandomizedSearchCV(estimator=model_gbr,\n",
    "#                                 param_distributions=param_grid,\n",
    "#                                 scoring='neg_mean_squared_error',\n",
    "#                                 n_jobs=-1,\n",
    "#                                 cv=5)\n",
    "    \n",
    "# #     for val in ['HEALTH', 'WEB', 'AUTO', 'FINANCE', 'EDUCATION', 'OIL', 'SERVICE']:\n",
    "#     df = data.train_df\n",
    "#     train_temp = df[df['industry']=='HEALTH']\n",
    "#     y_train_temp = train_temp.pop('salary')\n",
    "#     train_temp = train_temp.drop(['industry'],axis=1)\n",
    "\n",
    "# #     train_temp = train_temp.drop(['jobType', 'degree', 'major', 'industry'],axis=1)\n",
    "\n",
    "#     random_fit = random.fit(train_temp,y_train_temp)\n",
    "#     scores = random_fit.best_score_\n",
    "#     print(scores)\n",
    "#     score_total = score_total + scores\n",
    "#     print(random_fit.best_params_)\n",
    "        \n",
    "# #     score_avg = score_total/7\n",
    "# #     print('Average score')\n",
    "# #     print(score_avg)\n",
    "#     return scores\n",
    "\n",
    "# start_time = time.time()\n",
    "# scores = scoring_gbr_gs()\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA \n",
    "# jobType and salary with specific comparison with high school and no degree\n",
    "df_hs = df[(df.degree=='HIGH_SCHOOL') | (df.degree=='NONE')]\n",
    "f, ax = plt.subplots(figsize=(12,6.5))\n",
    "sns.boxplot(x='jobType',y='salary',hue='degree',data=df_hs, palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COMMENT OUT TESTING\n",
    "# index_salary_null = df[df['salary'].isnull()].index\n",
    "# df = df.drop(index_salary_null,axis=0)\n",
    "data.train_df[data.train_df['salary']<51]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# df.isnull().any()\n",
    "# df.info()\n",
    "# df.dtypes\n",
    "# df.shape\n",
    "# df.describe()\n",
    "# df.corr()['salary']\n",
    "# objective is to predict salary. Do we see patterns with salary level and milesFromMetropolis?\n",
    "# miles_summary = df.groupby('milesFromMetropolis')\n",
    "# miles_summary.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['jobType_le_sq'] = df['jobType_le']*df['jobType_le']\n",
    "# df['jobType_le_plus'] = df['jobType_le'] + df['jobType_le']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Correlation Matrix\n",
    "# corr = df[['jobType', 'degree', 'major', 'industry', 'yearsExperience', 'milesFromMetropolis', 'salary', 'industry_le']].corr()\n",
    "corr = df[['jobType', 'degree', 'major', 'industry', 'yearsExperience',\n",
    "       'milesFromMetropolis', 'salary', 'jobType_le', 'degree_le', 'major_le',\n",
    "       'industry_le']].corr()\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "df[['jobType', 'degree', 'major', 'industry', 'yearsExperience',\n",
    "       'milesFromMetropolis', 'salary', 'jobType_le', 'degree_le', 'major_le',\n",
    "       'industry_le']].corr()['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical: jobType (le), degree (le), major (le), industry (le), \n",
    "# Continuous: yearsExperience, milesFromMetropolis\n",
    "# Target: salary\n",
    "# jobType will show good correlation with salary\n",
    "# degree will show some correlation with salary\n",
    "# major will show very little correlation with salary\n",
    "# industry_le will have salary scattered everywhere. \n",
    "# yearsExperience will show correlation with salary\n",
    "# milesFromMetropolis will show correlation with salary\n",
    "\n",
    "# EDA\n",
    "# Boxplot of salary by profession\n",
    "f, ax = plt.subplots(figsize=(12,6.5))\n",
    "plt.title(\"Salary by Job Title\")\n",
    "sns.boxplot(x='jobType',y='salary', data=df, width=.3, color='#eeefff',\n",
    "            order=['JANITOR','JUNIOR','SENIOR','MANAGER','VICE_PRESIDENT','CFO','CTO','CEO'])\n",
    "sns.despine(offset=10,trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Boxplot of salary by profession\n",
    "f, ax = plt.subplots(figsize=(9,6.5))\n",
    "plt.title(\"Salary by Degree\")\n",
    "sns.boxplot(x='degree',y='salary', data=df, width=.25, color='#eeefff',\n",
    "            order=['NONE','HIGH_SCHOOL','BACHELORS','MASTERS','DOCTORAL']\n",
    "            )\n",
    "sns.despine(offset=9,trim=True)\n",
    "df['degree'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Boxplot of salary by major\n",
    "f, ax = plt.subplots(figsize=(12,6.5))\n",
    "plt.title(\"Salary by Major\")\n",
    "sns.boxplot(x='major',y='salary', data=df, width=.3, color='#eeefff',\n",
    "            order=['NONE', 'LITERATURE', 'BIOLOGY', 'CHEMISTRY', 'PHYSICS', 'COMPSCI',\n",
    "            'MATH', 'BUSINESS', 'ENGINEERING'])\n",
    "sns.despine(offset=10,trim=True)\n",
    "\n",
    "# # Create mean ascending ranking list for major\n",
    "# print(df.groupby('major').salary.mean().sort_values().keys())\n",
    "# df.groupby('major').salary.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Boxplot of salary by major\n",
    "f, ax = plt.subplots(figsize=(10,6.5))\n",
    "plt.title(\"Salary by Industry\")\n",
    "sns.boxplot(x='industry',y='salary', data=df, width=.3, color='#eeefff',\n",
    "            order=['EDUCATION', 'SERVICE', 'AUTO', 'HEALTH', 'WEB', 'FINANCE', 'OIL']\n",
    "           )\n",
    "sns.despine(offset=11,trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EDA\n",
    "# # There doesn't appear to be any patterns in salary based on companyId. \n",
    "# sns.boxplot(x='companyId',y='salary', data=df_companyid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# There is no sign that yearsExperience or milesFromMetropolis have differing ranking when boxplotted with \n",
    "# 'jobType', 'degree', 'major', 'industry'.\n",
    "\n",
    "f, axes = plt.subplots(ncols=2, figsize=(25,3))\n",
    "sns.boxplot(x='jobType', y='yearsExperience', data=df, ax=axes[0]).set_title('Experience Versus Job')\n",
    "sns.boxplot(x='degree', y='yearsExperience', data=df, ax=axes[1]).set_title('Experience Versus Degree');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "f, axes = plt.subplots(ncols=2, figsize=(25,3))\n",
    "sns.boxplot(x='major', y='yearsExperience', data=df, ax=axes[0]).set_title('Experience Versus Major')\n",
    "sns.boxplot(x='industry', y='yearsExperience', data=df, ax=axes[1]).set_title('Experience Versus Industry');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "f, axes = plt.subplots(ncols=2, figsize=(25,3))\n",
    "sns.boxplot(x='jobType', y='milesFromMetropolis', data=df, ax=axes[0]).set_title('Distance Versus Job')\n",
    "sns.boxplot(x='degree', y='milesFromMetropolis', data=df, ax=axes[1]).set_title('Distance Versus Degree');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "f, axes = plt.subplots(ncols=2, figsize=(25,3))\n",
    "sns.boxplot(x='major', y='milesFromMetropolis', data=df, ax=axes[0]).set_title('Distance Versus Major')\n",
    "sns.boxplot(x='industry', y='milesFromMetropolis', data=df, ax=axes[1]).set_title('Distance Versus Industry');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must look very carefully at the data and see opportunities to create more signal in the data that will make \n",
    "# the algorithm pick up on certain things that enhance accuracy of predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brainstorm 3 models that you think may improve results over the baseline model based\n",
    "# read documentation and determine good models to try "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model\n",
    "\n",
    "# FEATURE ENGINEERING NOTES \n",
    "# jobType - we've already created this features\n",
    "# degree - create feature, 0=high school, none, 1=others.\n",
    "# degree - create another feature, 0=high school, none, 1=bachelors,masters, 2=phd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and tune the models that you brainstormed during part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do 5-fold cross validation on models and measure MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"prodcuction\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
