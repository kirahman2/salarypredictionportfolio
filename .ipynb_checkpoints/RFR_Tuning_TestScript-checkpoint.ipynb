{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each algorithm needs to have its own class. Within each class, each needs to have its own hyperparameter\n",
    "# that we decide to tune. Finalize getting max_depth to accept an array. then build another method for n_estimators\n",
    "# Once we complete that, figure out how to auto select the best parameter, and automatically create the next\n",
    "# set of parameters to test\n",
    "class TuningRFR:\n",
    "    def __init__(self, df, col_target, col_id):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.train_test_split(df)\n",
    "        \n",
    "    def train_test_split(self, df):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop([col_target,col_id],axis=1),\n",
    "                                                                    df[col_target],\n",
    "                                                                    test_size=0.25)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def maxdepth(self, list_maxdepth):\n",
    "        results = []\n",
    "        counter = 0\n",
    "        for val in list_maxdepth:\n",
    "            model_temp = RandomForestRegressor(max_depth=val, verbose=False,\n",
    "                                               n_jobs=-1, random_state=42)\n",
    "            model_temp.fit(self.X_train, self.y_train)\n",
    "            results = self._create_dictionary(results, val, model_temp, 'max_depth', counter)\n",
    "            counter = counter + 1\n",
    "        results_df = self._create_dataframe(results, 'max_depth')\n",
    "        self._plot_results(results_df, 'max_depth')\n",
    "        return results_df\n",
    "    \n",
    "    def _create_dictionary(self, results, val, model_temp, hyperparameter, counter):\n",
    "        results.append(\n",
    "        {'temp': val,\n",
    "         'train_error': mean_squared_error(self.y_train, model_temp.predict(self.X_train)),\n",
    "         'test_error': mean_squared_error(self.y_test, model_temp.predict(self.X_test)),\n",
    "        })\n",
    "        temp = results[counter]\n",
    "        temp[hyperparameter] = temp.pop('temp')\n",
    "        return results\n",
    "# test this, remove _fixing word ext., comment out old nestimators, try again. then begin using standard\n",
    "# ways to tune models... Just have a separate notebook or something.. \n",
    "    def nestimators_fixing(self, list_nestimators):\n",
    "        results = []\n",
    "        counter = 0\n",
    "        for val in list_nestimators:\n",
    "            model_temp = RandomForestRegressor(n_estimators=val, verbose=False,\n",
    "                                               n_jobs=-1, random_state=42)\n",
    "            model_temp.fit(self.X_train, self.y_train)\n",
    "            results = self._create_dictionary(results, val, model_temp, 'n_estimators', counter)\n",
    "            counter = counter + 1\n",
    "        results_df = self._create_dataframe(results, 'n_estimators')\n",
    "        self._plot_results(results_df, 'n_estimators')\n",
    "        return results_df\n",
    "\n",
    "    def nestimators(self, list_nestimators):\n",
    "        results = []\n",
    "        for val in list_nestimators:\n",
    "            print(val)\n",
    "            model_temp = RandomForestRegressor(n_estimators=val, verbose=False,\n",
    "                                               n_jobs=-1, random_state=42)\n",
    "            model_temp.fit(self.X_train, self.y_train)\n",
    "            results.append(\n",
    "            {'n_estimators': val,\n",
    "             'train_error': mean_squared_error(self.y_train, model_temp.predict(self.X_train)),\n",
    "             'test_error': mean_squared_error(self.y_test, model_temp.predict(self.X_test)),\n",
    "            })\n",
    "        results_df = self._create_dataframe(results, 'n_estimators')\n",
    "        self._plot_results(results_df, 'n_estimators')\n",
    "        return results_df\n",
    "    \n",
    "    def maxfeatures(self, list_maxfeatures):\n",
    "        results = []\n",
    "        counter = 0\n",
    "        for val in list_maxfeatures:\n",
    "            model_temp = RandomForestRegressor(max_features=val, verbose=False,\n",
    "                                               n_jobs=-1, random_state=42)\n",
    "            model_temp.fit(self.X_train, self.y_train)\n",
    "#             results = self._create_dictionary(results, val, model_temp, 'max_features')\n",
    "            \n",
    "            results.append(\n",
    "            {'max_features': val,\n",
    "             'train_error': mean_squared_error(self.y_train, model_temp.predict(self.X_train)),\n",
    "             'test_error': mean_squared_error(self.y_test, model_temp.predict(self.X_test)),\n",
    "            })\n",
    "        results_df = self._create_dataframe(results, 'max_features')\n",
    "        self._plot_results(results_df, 'max_features')\n",
    "        return results_df\n",
    "    \n",
    "    def minsamplesleaf(self, list_minsamplesleaf):\n",
    "        results = []\n",
    "        for val in list_minsamplesleaf:\n",
    "            model_temp = RandomForestRegressor(min_samples_leaf=val, verbose=False,\n",
    "                                               n_jobs=-1, random_state=42)\n",
    "            model_temp.fit(self.X_train, self.y_train)\n",
    "#             results = self._create_dictionary(results, val, model_temp, 'min_samples_leaf')\n",
    "            results.append(\n",
    "            {'min_samples_leaf': val,\n",
    "             'train_error': mean_squared_error(self.y_train, model_temp.predict(self.X_train)),\n",
    "             'test_error': mean_squared_error(self.y_test, model_temp.predict(self.X_test)),\n",
    "            })\n",
    "        results_df = self._create_dataframe(results, 'min_samples_leaf')\n",
    "        self._plot_results(results_df, 'min_samples_leaf')\n",
    "        return results_df\n",
    "    \n",
    "    def _create_dataframe(self, results, hyperparameter):\n",
    "        return pd.DataFrame(results).set_index(hyperparameter).sort_index()\n",
    "        \n",
    "    def _plot_results(self, results_df, hyperparameter):\n",
    "        results_df.plot(title=hyperparameter + ' score')\n",
    "        \n",
    "tuning_rfr = TuningRFR(data.train_df, col_target, col_id)\n",
    "# tuning_rfg.nestimators(range(1,3))\n",
    "# tuning_rfg.maxfeatures([\"auto\", None, \"sqrt\"])\n",
    "# tuning_rfr.nestimators(range(2,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
