{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GBR RandomizedSearchCV READY #####\n",
    "y_train = data.train_df[col_target]\n",
    "X_train = data.train_df.drop([col_target,col_id],axis=1)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "learning_rate= [.5,.6,.7]\n",
    "n_estimators= [110,111,112]\n",
    "subsample= [.83,.84,.85]\n",
    "max_depth= [10,11,12]\n",
    "max_leaf_nodes= [6,7,8]\n",
    "\n",
    "hyperparameters = dict(learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                       subsample=subsample, max_depth=max_depth, max_leaf_nodes=max_leaf_nodes\n",
    "                      )\n",
    "\n",
    "clf = RandomizedSearchCV(gbr, hyperparameters, random_state=42, cv=3, verbose=1, n_jobs=-1)\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# best hyper parameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['subsample'])\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['max_leaf_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split set for tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.train_df.drop([col_target,col_id],axis=1), \n",
    "                                                    data.train_df[col_target], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETE\n",
    "# best max_depth=[]                                                  ###\n",
    "hyperp = 'max_depth'                                                 ###\n",
    "list_val = range(1,10,2)\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(max_depth=val, loss='huber',           ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETE\n",
    "# best loss=['huber']                                                  ###\n",
    "hyperp = 'loss'                                                 ###\n",
    "list_val = ['ls', 'lad', 'huber', 'quantile']\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(loss=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth \n",
    "# best learning_rate=                                                    ###\n",
    "hyperp = 'learning_rate'                                                 ###\n",
    "list_val = [.01,.05,.1,.2,.5,.9]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(learning_rate=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETE\n",
    "# best n_estimators= [70,72,74]                                                   ###\n",
    "hyperp = 'n_estimators'                                                 ###\n",
    "list_val = range(1,110,20)\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(n_estimators=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETEF\n",
    "# best subsample=[.7,.8,1]                                                   ###\n",
    "hyperp = 'subsample'                                                 ###\n",
    "list_val = [.1,.3,.5,.7,1]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(subsample=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best criterion=                                             ###\n",
    "results = []\n",
    "list_values = ['friedman_mse', 'mse']\n",
    "hyperp = 'criterion'                                          ###\n",
    "for val in list_values:\n",
    "    gbr = GradientBoostingRegressor(criterion=val, verbose=0, random_state=42) ###\n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "    {'criterion': val,                                        ###\n",
    "     'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "     'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "    })\n",
    "    print(val)\n",
    "    print(pd.DataFrame(results))\n",
    "result_final = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "result_final.plot(title=hyperp + ' Learning Curve')\n",
    "result_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETE\n",
    "# best min_samples_split=default                                                    ###\n",
    "hyperp = 'min_samples_split'                                                 ###\n",
    "list_val = range(2,20,3)\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(min_samples_split=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val, \n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth COMPLETE\n",
    "# best min_samples_leaf=default                                                    ###\n",
    "hyperp = 'min_samples_leaf'                                                 ###\n",
    "list_val = range(2,12,2)\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(min_samples_leaf=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth \n",
    "# best min_weight_fraction_leaf=default                                                    ###\n",
    "hyperp = 'min_weight_fraction_leaf'                                                 ###\n",
    "list_val = [0,.1,.2,.3,.4,.5]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(min_weight_fraction_leaf=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth \n",
    "# best min_impurity_decrease=[0,.1] #improves time                                                    ###\n",
    "hyperp = 'min_impurity_decrease'                                                 ###\n",
    "list_val = [0,.1,.5,.7,.9]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(min_impurity_decrease=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr +maxdepth \n",
    "# best max_features=[auto, log2]                                                    ###\n",
    "hyperp = 'max_features'                                                 ###\n",
    "list_val = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(max_features=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thisgbr +maxdepth \n",
    "# best alpha=default                                                    ###\n",
    "hyperp = 'alpha'                                                 ###\n",
    "list_val = [.1,.5,.9]\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(alpha=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thisgbr +maxdepth \n",
    "# best max_leaf_nodes=                                                    ###\n",
    "hyperp = 'max_leaf_nodes'                                                 ###\n",
    "# list_val = [None]\n",
    "# list_val = range(100,500,100)\n",
    "list_val = range(10,100,10)\n",
    "\n",
    "results=[]\n",
    "for val in list_val:\n",
    "    start_time = time.time()\n",
    "    gbr = GradientBoostingRegressor(max_leaf_nodes=val, max_depth=7,          ###\n",
    "                                    random_state=42, verbose=0) \n",
    "    gbr.fit(X_train, y_train)\n",
    "    results.append(\n",
    "        {\n",
    "            hyperp: val,                                         ###\n",
    "            'train_error': mean_squared_error(y_train, gbr.predict(X_train)),\n",
    "            'test_error': mean_squared_error(y_test, gbr.predict(X_test)),\n",
    "            'minutes': (time.time() - start_time)/60\n",
    "        })\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "results = pd.DataFrame(results).set_index(hyperp).sort_index()\n",
    "results[['train_error','test_error']].plot(title=hyperp + ' MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
